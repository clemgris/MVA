{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yl3p_9CR1Os-","executionInfo":{"status":"ok","timestamp":1669754081317,"user_tz":-60,"elapsed":17972,"user":{"displayName":"clemence grislain","userId":"13746602164428450753"}},"outputId":"e53180c2-bcb3-4dd3-b503-be48e0b38e57"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## Install requiered packages"],"metadata":{"id":"aqhhvnLL9wsq"}},{"cell_type":"code","source":["!python -m pip install pyyaml==5.1\n","!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n","!pip install -r \"/content/drive/MyDrive/recvis22_a3/requirements.txt\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_U4ocbL12lX","outputId":"b2fd3069-c89c-4e07-ea0b-7a6456d5efd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyyaml==5.1\n","  Downloading PyYAML-5.1.tar.gz (274 kB)\n","\u001b[K     |████████████████████████████████| 274 kB 4.6 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyyaml\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44090 sha256=293adb190cf66674f702ef5589def224dd72ed63641f5dacdf3a15fab6d3054a\n","  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n","Successfully built pyyaml\n","Installing collected packages: pyyaml\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","dask 2022.2.0 requires pyyaml>=5.3.1, but you have pyyaml 5.1 which is incompatible.\u001b[0m\n","Successfully installed pyyaml-5.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/facebookresearch/detectron2.git\n","  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-gc3bs32p\n","  Running command git clone -q https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-gc3bs32p\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (7.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (3.2.2)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.0.6)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.1.0)\n","Collecting yacs>=0.1.8\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.8.10)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.5.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (4.64.1)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.9.1)\n","Collecting fvcore<0.1.6,>=0.1.5\n","  Downloading fvcore-0.1.5.post20221122.tar.gz (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 3.3 MB/s \n","\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n","  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.16.0)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n","Collecting omegaconf>=2.1\n","  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 7.1 MB/s \n","\u001b[?25hCollecting hydra-core>=1.1\n","  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 42.7 MB/s \n","\u001b[?25hCollecting black==22.3.0\n","  Downloading black-22.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 63.4 MB/s \n","\u001b[?25hCollecting timm\n","  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n","\u001b[K     |████████████████████████████████| 549 kB 65.9 MB/s \n","\u001b[?25hCollecting fairscale\n","  Downloading fairscale-0.4.6.tar.gz (248 kB)\n","\u001b[K     |████████████████████████████████| 248 kB 76.8 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (21.3)\n","Collecting mypy-extensions>=0.4.3\n","  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n","Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from black==22.3.0->detectron2==0.6) (4.1.1)\n","Collecting pathspec>=0.9.0\n","  Downloading pathspec-0.10.2-py3-none-any.whl (28 kB)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from black==22.3.0->detectron2==0.6) (2.0.1)\n","Collecting typed-ast>=1.4.2\n","  Downloading typed_ast-1.5.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n","\u001b[K     |████████████████████████████████| 843 kB 53.8 MB/s \n","\u001b[?25hCollecting click>=8.0.0\n","  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n","\u001b[K     |████████████████████████████████| 96 kB 7.4 MB/s \n","\u001b[?25hCollecting platformdirs>=2\n","  Downloading platformdirs-2.5.4-py3-none-any.whl (14 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click>=8.0.0->black==22.3.0->detectron2==0.6) (4.13.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.21.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (5.1)\n","Collecting antlr4-python3-runtime==4.9.*\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 66.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2==0.6) (5.10.0)\n","Collecting portalocker\n","  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (1.4.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2==0.6) (1.15.0)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from fairscale->detectron2==0.6) (1.12.1+cu113)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click>=8.0.0->black==22.3.0->detectron2==0.6) (3.10.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.3.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.50.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.38.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (57.4.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (2.14.1)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.19.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.4.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.2.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2022.9.24)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.2.2)\n","Collecting huggingface-hub\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 68.3 MB/s \n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm->detectron2==0.6) (0.13.1+cu113)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm->detectron2==0.6) (3.8.0)\n","Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime, fairscale\n"]}]},{"cell_type":"code","source":["import torch\n","torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gNZmZn5n2HA-","executionInfo":{"status":"ok","timestamp":1669718984305,"user_tz":-60,"elapsed":464,"user":{"displayName":"clemence grislain","userId":"13746602164428450753"}},"outputId":"98a175a6-7dfd-43a7-a22c-4d931c012902"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## Visualize data"],"metadata":{"id":"CCcbp9AxkdHH"}},{"cell_type":"code","source":["import os\n","import cv2\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","path = \"/content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/\"\n","\n","fig = plt.figure(figsize=(20, 10))\n","\n","j = 1\n","for fold in os.listdir(path + \"bird_dataset/train_images/\"):\n","    for data in os.listdir(path + \"bird_dataset/train_images/\" + fold + \"/\"):\n","        fig.add_subplot(4,5,j)\n","        im = cv2.imread(path + \"bird_dataset/train_images/\" +  fold + \"/\" + data)\n","        plt.imshow(im)\n","        j = j+ 1\n","        break\n","    if j > 20: break\n","\n","plt.suptitle(\"Training data\", fontweight=\"bold\", fontsize=20)\n","\n","fig = plt.figure(figsize=(20, 10))\n","\n","j = 1\n","for fold in os.listdir(path + \"bird_dataset/val_images/\"):\n","    for data in os.listdir(path + \"bird_dataset/val_images/\" + fold + \"/\"):\n","        fig.add_subplot(4,5,j)\n","        im = cv2.imread(path + \"bird_dataset/val_images/\" +  fold + \"/\" + data)\n","        plt.imshow(im)\n","        j = j+ 1\n","        break\n","    if j > 20: break\n","\n","plt.suptitle(\"Validation data\", fontweight=\"bold\", fontsize=20)\n","\n","fig = plt.figure(figsize=(20,10))\n","\n","j = 1\n","for fold in os.listdir(path + \"bird_dataset/test_images/\"):\n","    for data in os.listdir(path + \"bird_dataset/test_images/\" + fold + \"/\"):\n","        fig.add_subplot(4,5,j)\n","        im = cv2.imread(path + \"bird_dataset/test_images/\" +  fold + \"/\" + data)\n","        plt.imshow(im)\n","        j += 1\n","        if j > 20: break\n","        \n","plt.suptitle(\"Testing data\", fontweight=\"bold\", fontsize=20)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1xj6SG1GPtvZB5rSRJfpVNq4Wh9S4U_3d"},"id":"cw7ttWFskcqI","executionInfo":{"status":"ok","timestamp":1669729963588,"user_tz":-60,"elapsed":9815,"user":{"displayName":"Clémence Grislain","userId":"11403236412154413898"}},"outputId":"eb995cb1-c9ae-4c05-c4bb-e104609427b3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["## Create new dataset centered on birds object"],"metadata":{"id":"JQZmT6_H8GaC"}},{"cell_type":"code","source":["!python \"/content/drive/MyDrive/recvis22_a3/center_dataset.py\""],"metadata":{"id":"Iq4QUYPv8Mvy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669754127743,"user_tz":-60,"elapsed":4980,"user":{"displayName":"clemence grislain","userId":"13746602164428450753"}},"outputId":"e9e3f067-a004-4d7f-a8ca-0faabbcb2ff7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/recvis22_a3/center_dataset.py\", line 5, in <module>\n","    from detectron2 import model_zoo\n","ModuleNotFoundError: No module named 'detectron2'\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","path = \"/content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/\"\n","\n","fig = plt.figure(figsize=(20, 10))\n","\n","j = 1\n","for fold in os.listdir(path + \"bird_dataset_centered/train_images/\"):\n","    for data in os.listdir(path + \"bird_dataset_centered/train_images/\" + fold + \"/\"):\n","        fig.add_subplot(4,5,j)\n","        im = cv2.imread(path + \"bird_dataset_centered/train_images/\" +  fold + \"/\" + data)\n","        plt.imshow(im)\n","        j = j+ 1\n","        break\n","    if j > 20: break\n","\n","plt.suptitle(\"Training centered data\", fontweight=\"bold\", fontsize=20)\n","\n","fig = plt.figure(figsize=(20, 10))\n","\n","j = 1\n","for fold in os.listdir(path + \"bird_dataset_centered/val_images/\"):\n","    for data in os.listdir(path + \"bird_dataset_centered/val_images/\" + fold + \"/\"):\n","        fig.add_subplot(4,5,j)\n","        im = cv2.imread(path + \"bird_dataset_centered/val_images/\" +  fold + \"/\" + data)\n","        plt.imshow(im)\n","        j = j+ 1\n","        break\n","    if j > 20: break\n","\n","plt.suptitle(\"Validation centered data\", fontweight=\"bold\", fontsize=20)\n","\n","fig = plt.figure(figsize=(20,10))\n","\n","j = 1\n","for fold in os.listdir(path + \"bird_dataset_centered/test_images/\"):\n","    for data in os.listdir(path + \"bird_dataset_centered/test_images/\" + fold + \"/\"):\n","        fig.add_subplot(4,5,j)\n","        im = cv2.imread(path + \"bird_dataset_centered/test_images/\" +  fold + \"/\" + data)\n","        plt.imshow(im)\n","        j += 1\n","        if j > 20: break\n","        \n","plt.suptitle(\"Testing centered data\", fontweight=\"bold\", fontsize=20)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"15XbeY8dQmnTVdpJz2yAyG8csKgBQF4wg"},"id":"a95t7YG1qCzw","executionInfo":{"status":"ok","timestamp":1669730023817,"user_tz":-60,"elapsed":26013,"user":{"displayName":"Clémence Grislain","userId":"11403236412154413898"}},"outputId":"0d69ad87-28ed-4fd6-fff7-86aba6643ec6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["## Train model on centered dataset"],"metadata":{"id":"9re-609M8Wmh"}},{"cell_type":"code","source":["!python \"/content/drive/MyDrive/recvis22_a3/main.py\" --data '/content/drive/MyDrive/recvis22_a3/bird_dataset_centered' --epochs 20 --lr 0.001 --batch-size 16"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4JOeYpBDZbfC","executionInfo":{"status":"ok","timestamp":1669725175022,"user_tz":-60,"elapsed":684472,"user":{"displayName":"clemence grislain","userId":"13746602164428450753"}},"outputId":"9615d6e7-dd3d-497a-f57f-b9e087d600ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data: /content/drive/MyDrive/recvis22_a3/bird_dataset_centered\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:136: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and will be removed in 0.15. Please use keyword parameter(s) instead.\n","  f\"Using {sequence_to_str(tuple(keyword_only_kwargs.keys()), separate_last='and ')} as positional \"\n","Using GPU\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","Train Epoch: 1 [0/1082 (0%)]\tLoss: 2.945699\n","Train Epoch: 1 [160/1082 (15%)]\tLoss: 2.277768\n","Train Epoch: 1 [320/1082 (29%)]\tLoss: 1.087280\n","Train Epoch: 1 [480/1082 (44%)]\tLoss: 0.583002\n","Train Epoch: 1 [640/1082 (59%)]\tLoss: 0.942104\n","Train Epoch: 1 [800/1082 (74%)]\tLoss: 0.679699\n","Train Epoch: 1 [960/1082 (88%)]\tLoss: 0.439039\n","\n","Validation set: Average loss: 0.0281, Accuracy: 84/103 (82%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_1.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_1.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 2 [0/1082 (0%)]\tLoss: 0.662467\n","Train Epoch: 2 [160/1082 (15%)]\tLoss: 0.247449\n","Train Epoch: 2 [320/1082 (29%)]\tLoss: 0.377519\n","Train Epoch: 2 [480/1082 (44%)]\tLoss: 0.316538\n","Train Epoch: 2 [640/1082 (59%)]\tLoss: 0.404831\n","Train Epoch: 2 [800/1082 (74%)]\tLoss: 0.117019\n","Train Epoch: 2 [960/1082 (88%)]\tLoss: 0.293555\n","\n","Validation set: Average loss: 0.0212, Accuracy: 91/103 (88%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_2.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_2.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 3 [0/1082 (0%)]\tLoss: 0.334649\n","Train Epoch: 3 [160/1082 (15%)]\tLoss: 0.269371\n","Train Epoch: 3 [320/1082 (29%)]\tLoss: 0.357281\n","Train Epoch: 3 [480/1082 (44%)]\tLoss: 0.212008\n","Train Epoch: 3 [640/1082 (59%)]\tLoss: 0.254700\n","Train Epoch: 3 [800/1082 (74%)]\tLoss: 0.710251\n","Train Epoch: 3 [960/1082 (88%)]\tLoss: 0.384311\n","\n","Validation set: Average loss: 0.0284, Accuracy: 91/103 (88%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_3.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_3.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 4 [0/1082 (0%)]\tLoss: 0.107325\n","Train Epoch: 4 [160/1082 (15%)]\tLoss: 0.300301\n","Train Epoch: 4 [320/1082 (29%)]\tLoss: 0.075519\n","Train Epoch: 4 [480/1082 (44%)]\tLoss: 0.347304\n","Train Epoch: 4 [640/1082 (59%)]\tLoss: 0.008721\n","Train Epoch: 4 [800/1082 (74%)]\tLoss: 0.176665\n","Train Epoch: 4 [960/1082 (88%)]\tLoss: 0.112594\n","\n","Validation set: Average loss: 0.0218, Accuracy: 92/103 (89%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_4.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_4.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 5 [0/1082 (0%)]\tLoss: 0.505670\n","Train Epoch: 5 [160/1082 (15%)]\tLoss: 0.182261\n","Train Epoch: 5 [320/1082 (29%)]\tLoss: 0.357916\n","Train Epoch: 5 [480/1082 (44%)]\tLoss: 0.115045\n","Train Epoch: 5 [640/1082 (59%)]\tLoss: 0.090410\n","Train Epoch: 5 [800/1082 (74%)]\tLoss: 0.318898\n","Train Epoch: 5 [960/1082 (88%)]\tLoss: 0.219947\n","\n","Validation set: Average loss: 0.0226, Accuracy: 88/103 (85%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_5.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_5.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 6 [0/1082 (0%)]\tLoss: 0.234205\n","Train Epoch: 6 [160/1082 (15%)]\tLoss: 0.043225\n","Train Epoch: 6 [320/1082 (29%)]\tLoss: 0.092377\n","Train Epoch: 6 [480/1082 (44%)]\tLoss: 0.019660\n","Train Epoch: 6 [640/1082 (59%)]\tLoss: 0.072058\n","Train Epoch: 6 [800/1082 (74%)]\tLoss: 0.305364\n","Train Epoch: 6 [960/1082 (88%)]\tLoss: 0.061408\n","\n","Validation set: Average loss: 0.0193, Accuracy: 92/103 (89%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_6.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_6.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 7 [0/1082 (0%)]\tLoss: 0.098970\n","Train Epoch: 7 [160/1082 (15%)]\tLoss: 0.022216\n","Train Epoch: 7 [320/1082 (29%)]\tLoss: 0.261165\n","Train Epoch: 7 [480/1082 (44%)]\tLoss: 0.050846\n","Train Epoch: 7 [640/1082 (59%)]\tLoss: 0.022390\n","Train Epoch: 7 [800/1082 (74%)]\tLoss: 0.398751\n","Train Epoch: 7 [960/1082 (88%)]\tLoss: 0.020530\n","\n","Validation set: Average loss: 0.0145, Accuracy: 93/103 (90%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_7.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_7.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 8 [0/1082 (0%)]\tLoss: 0.007166\n","Train Epoch: 8 [160/1082 (15%)]\tLoss: 0.027800\n","Train Epoch: 8 [320/1082 (29%)]\tLoss: 0.010046\n","Train Epoch: 8 [480/1082 (44%)]\tLoss: 0.017456\n","Train Epoch: 8 [640/1082 (59%)]\tLoss: 0.015234\n","Train Epoch: 8 [800/1082 (74%)]\tLoss: 0.008713\n","Train Epoch: 8 [960/1082 (88%)]\tLoss: 0.004420\n","\n","Validation set: Average loss: 0.0183, Accuracy: 92/103 (89%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_8.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_8.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 9 [0/1082 (0%)]\tLoss: 0.002479\n","Train Epoch: 9 [160/1082 (15%)]\tLoss: 0.026456\n","Train Epoch: 9 [320/1082 (29%)]\tLoss: 0.075840\n","Train Epoch: 9 [480/1082 (44%)]\tLoss: 0.009080\n","Train Epoch: 9 [640/1082 (59%)]\tLoss: 0.008498\n","Train Epoch: 9 [800/1082 (74%)]\tLoss: 0.010864\n","Train Epoch: 9 [960/1082 (88%)]\tLoss: 0.115902\n","\n","Validation set: Average loss: 0.0176, Accuracy: 95/103 (92%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_9.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_9.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 10 [0/1082 (0%)]\tLoss: 0.006715\n","Train Epoch: 10 [160/1082 (15%)]\tLoss: 0.067227\n","Train Epoch: 10 [320/1082 (29%)]\tLoss: 0.012668\n","Train Epoch: 10 [480/1082 (44%)]\tLoss: 0.004379\n","Train Epoch: 10 [640/1082 (59%)]\tLoss: 0.045696\n","Train Epoch: 10 [800/1082 (74%)]\tLoss: 0.009876\n","Train Epoch: 10 [960/1082 (88%)]\tLoss: 0.046049\n","\n","Validation set: Average loss: 0.0147, Accuracy: 93/103 (90%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_10.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_10.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 11 [0/1082 (0%)]\tLoss: 0.001799\n","Train Epoch: 11 [160/1082 (15%)]\tLoss: 0.001200\n","Train Epoch: 11 [320/1082 (29%)]\tLoss: 0.005694\n","Train Epoch: 11 [480/1082 (44%)]\tLoss: 0.005904\n","Train Epoch: 11 [640/1082 (59%)]\tLoss: 0.010104\n","Train Epoch: 11 [800/1082 (74%)]\tLoss: 0.001120\n","Train Epoch: 11 [960/1082 (88%)]\tLoss: 0.010820\n","\n","Validation set: Average loss: 0.0154, Accuracy: 93/103 (90%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_11.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_11.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 12 [0/1082 (0%)]\tLoss: 0.001488\n","Train Epoch: 12 [160/1082 (15%)]\tLoss: 0.001292\n","Train Epoch: 12 [320/1082 (29%)]\tLoss: 0.008409\n","Train Epoch: 12 [480/1082 (44%)]\tLoss: 0.029425\n","Train Epoch: 12 [640/1082 (59%)]\tLoss: 0.001986\n","Train Epoch: 12 [800/1082 (74%)]\tLoss: 0.018593\n","Train Epoch: 12 [960/1082 (88%)]\tLoss: 0.021426\n","\n","Validation set: Average loss: 0.0157, Accuracy: 92/103 (89%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_12.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_12.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 13 [0/1082 (0%)]\tLoss: 0.070910\n","Train Epoch: 13 [160/1082 (15%)]\tLoss: 0.003067\n","Train Epoch: 13 [320/1082 (29%)]\tLoss: 0.006036\n","Train Epoch: 13 [480/1082 (44%)]\tLoss: 0.001995\n","Train Epoch: 13 [640/1082 (59%)]\tLoss: 0.002660\n","Train Epoch: 13 [800/1082 (74%)]\tLoss: 0.003395\n","Train Epoch: 13 [960/1082 (88%)]\tLoss: 0.000457\n","\n","Validation set: Average loss: 0.0142, Accuracy: 95/103 (92%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_13.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_13.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 14 [0/1082 (0%)]\tLoss: 0.001881\n","Train Epoch: 14 [160/1082 (15%)]\tLoss: 0.002173\n","Train Epoch: 14 [320/1082 (29%)]\tLoss: 0.004940\n","Train Epoch: 14 [480/1082 (44%)]\tLoss: 0.000665\n","Train Epoch: 14 [640/1082 (59%)]\tLoss: 0.001747\n","Train Epoch: 14 [800/1082 (74%)]\tLoss: 0.014915\n","Train Epoch: 14 [960/1082 (88%)]\tLoss: 0.002629\n","\n","Validation set: Average loss: 0.0142, Accuracy: 95/103 (92%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_14.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_14.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 15 [0/1082 (0%)]\tLoss: 0.000913\n","Train Epoch: 15 [160/1082 (15%)]\tLoss: 0.000752\n","Train Epoch: 15 [320/1082 (29%)]\tLoss: 0.001059\n","Train Epoch: 15 [480/1082 (44%)]\tLoss: 0.003032\n","Train Epoch: 15 [640/1082 (59%)]\tLoss: 0.000831\n","Train Epoch: 15 [800/1082 (74%)]\tLoss: 0.011685\n","Train Epoch: 15 [960/1082 (88%)]\tLoss: 0.000923\n","\n","Validation set: Average loss: 0.0156, Accuracy: 93/103 (90%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_15.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_15.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 16 [0/1082 (0%)]\tLoss: 0.005304\n","Train Epoch: 16 [160/1082 (15%)]\tLoss: 0.009627\n","Train Epoch: 16 [320/1082 (29%)]\tLoss: 0.002148\n","Train Epoch: 16 [480/1082 (44%)]\tLoss: 0.043684\n","Train Epoch: 16 [640/1082 (59%)]\tLoss: 0.006315\n","Train Epoch: 16 [800/1082 (74%)]\tLoss: 0.024523\n","Train Epoch: 16 [960/1082 (88%)]\tLoss: 0.000313\n","\n","Validation set: Average loss: 0.0128, Accuracy: 96/103 (93%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_16.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_16.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 17 [0/1082 (0%)]\tLoss: 0.003696\n","Train Epoch: 17 [160/1082 (15%)]\tLoss: 0.057152\n","Train Epoch: 17 [320/1082 (29%)]\tLoss: 0.016537\n","Train Epoch: 17 [480/1082 (44%)]\tLoss: 0.010392\n","Train Epoch: 17 [640/1082 (59%)]\tLoss: 0.001441\n","Train Epoch: 17 [800/1082 (74%)]\tLoss: 0.005339\n","Train Epoch: 17 [960/1082 (88%)]\tLoss: 0.001515\n","\n","Validation set: Average loss: 0.0131, Accuracy: 94/103 (91%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_17.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_17.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 18 [0/1082 (0%)]\tLoss: 0.008233\n","Train Epoch: 18 [160/1082 (15%)]\tLoss: 0.003198\n","Train Epoch: 18 [320/1082 (29%)]\tLoss: 0.000498\n","Train Epoch: 18 [480/1082 (44%)]\tLoss: 0.018357\n","Train Epoch: 18 [640/1082 (59%)]\tLoss: 0.000654\n","Train Epoch: 18 [800/1082 (74%)]\tLoss: 0.000928\n","Train Epoch: 18 [960/1082 (88%)]\tLoss: 0.000461\n","\n","Validation set: Average loss: 0.0142, Accuracy: 96/103 (93%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_18.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_18.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 19 [0/1082 (0%)]\tLoss: 0.000112\n","Train Epoch: 19 [160/1082 (15%)]\tLoss: 0.002167\n","Train Epoch: 19 [320/1082 (29%)]\tLoss: 0.000589\n","Train Epoch: 19 [480/1082 (44%)]\tLoss: 0.007724\n","Train Epoch: 19 [640/1082 (59%)]\tLoss: 0.001402\n","Train Epoch: 19 [800/1082 (74%)]\tLoss: 0.004593\n","Train Epoch: 19 [960/1082 (88%)]\tLoss: 0.003152\n","\n","Validation set: Average loss: 0.0125, Accuracy: 96/103 (93%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_19.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_19.pth` to generate the Kaggle formatted csv file\n","\n","Train Epoch: 20 [0/1082 (0%)]\tLoss: 0.002552\n","Train Epoch: 20 [160/1082 (15%)]\tLoss: 0.001247\n","Train Epoch: 20 [320/1082 (29%)]\tLoss: 0.002382\n","Train Epoch: 20 [480/1082 (44%)]\tLoss: 0.001514\n","Train Epoch: 20 [640/1082 (59%)]\tLoss: 0.001776\n","Train Epoch: 20 [800/1082 (74%)]\tLoss: 0.002615\n","Train Epoch: 20 [960/1082 (88%)]\tLoss: 0.000184\n","\n","Validation set: Average loss: 0.0119, Accuracy: 96/103 (93%)\n","Saved model to /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_20.pth. You can run `python evaluate.py --model /content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_20.pth` to generate the Kaggle formatted csv file\n","\n"]}]},{"cell_type":"markdown","source":["## Evaluate model"],"metadata":{"id":"8edbFv-hpvH-"}},{"cell_type":"code","source":["!python \"/content/drive/MyDrive/recvis22_a3/evaluate.py\" --data '/content/drive/MyDrive/recvis22_a3/bird_dataset_centered' --model \"/content/drive/MyDrive/Colab Notebooks/MVA/OBJECT RECOGNITION/recvis22_a3/experiments/model_20.pth\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LiwORPL9HAhQ","executionInfo":{"status":"ok","timestamp":1669725443162,"user_tz":-60,"elapsed":25197,"user":{"displayName":"clemence grislain","userId":"13746602164428450753"}},"outputId":"5e2ce937-ae50-41bd-c690-5b0b221ab414"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:136: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and will be removed in 0.15. Please use keyword parameter(s) instead.\n","  f\"Using {sequence_to_str(tuple(keyword_only_kwargs.keys()), separate_last='and ')} as positional \"\n","Using GPU\n","Evaluate on /content/drive/MyDrive/recvis22_a3/bird_dataset_centered\n","100% 517/517 [00:19<00:00, 26.02it/s]\n","Succesfully wrote /content/drive/MyDrive/recvis22_a3/experiments/kaggle.csv, you can upload this file to the kaggle competition website\n"]}]}]}